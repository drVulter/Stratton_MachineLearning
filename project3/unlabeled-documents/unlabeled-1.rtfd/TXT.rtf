{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\froman\fcharset0 Times-Roman;\f1\fswiss\fcharset0 ArialMT;\f2\fmodern\fcharset0 Courier;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;\red255\green255\blue136;
}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c100000\c100000\c100000;\cssrgb\c100000\c100000\c60000;
}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid101\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid201\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid301\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid401\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid501\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid601\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid701\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid801\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid901\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1001\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid1101\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid12}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}}
\margl1440\margr1440\vieww17200\viewh9720\viewkind0
\deftab720
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f0\fs26\fsmilli13333 \cf2 \expnd0\expndtw0\kerning0
The Semantic Web relies heavily on the formal ontologies that structure underlying data for the purpose of comprehensive and transportable machine understanding. Therefore, the success of the Semantic Web depends strongly on the proliferation of ontologies, which requires fast and easy engineering of ontologies and avoidance of a knowledge acquisition bottleneck. 
\fs24 \
\pard\pardeftab720\sl300\sa240\partightenfactor0

\i\fs26\fsmilli13333 \cf2 Ontology Learning 
\i0 greatly facilitates the construction of ontologies by the ontology engineer. The vision of ontology learning that we propose here includes a number of complementary dis- ciplines that feed on different types of unstructured, semi-structured and fully structured data in order to support a semi-automatic, cooperative ontology engineering process. Our ontology learn- ing framework proceeds through ontology import, extraction, pruning, refinement, and evaluation giving the ontology engineer a wealth of coordinated tools for ontology modeling. Besides of the general framework and architecture, we show in this paper some exemplary techniques in the ontology learning cycle that we have implemented in our ontology learning environment, 
\i Text-To- Onto
\i0 , such as ontology learning from free text, from dictionaries, or from legacy ontologies, and refer to some others that need to complement the complete architecture, such as reverse engineer- ing of ontologies from database schemata or learning from XML documents. 
\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 Ontologies for the Semantic Web 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Conceptual structures that define an underlying 
\i ontology 
\i0 are germane to the idea of machine process- able data on the Semantic Web. Ontologies are (meta)data schemas, providing a controlled vocabulary of concepts, each with an explicitly defined and machine processable semantics. By defining shared and common domain theories, ontologies help both people and machines to communicate concisely, 
\fs24 \

\fs29\fsmilli14667 1 
\fs24 \

\fs29\fsmilli14667 supporting the exchange of semantics and not only syntax. Hence, the cheap and fast construction of domain-specific ontologies is crucial for the success and the proliferation of the Semantic Web. 
\fs24 \

\fs29\fsmilli14667 Though ontology engineering tools have become mature over the last decade (cf. [2]), the manual acquisition of ontologies still remains a tedious, cumbersome task resulting easily in a 
\i knowledge acquisition bottleneck
\i0 . Having developed our ontology engineering workbench, 
\i OntoEdit
\i0 , we had to face exactly this issue, in particular we were given questions like 
\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls1\ilvl0\cf2 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 Can you develop an ontology fast? (time) 
\fs24 \uc0\u8232 \
\ls1\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 Is it difficult to build an ontology? (difficulty) 
\fs24 \uc0\u8232 \
\ls1\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 How do you know that you\'92ve got the ontology right? (confidence) 
\fs24 \uc0\u8232 
\fs29\fsmilli14667 In fact, these problems on time, difficulty and confidence that we ended up with were similar to what knowledge engineers had dealt with over the last two decades when they elaborated on method- ologies for knowledge acquisition or workbenches for defining knowledge bases. A method that proved extremely beneficial for the knowledge acquisition task was the integration of knowledge ac- quisition with machine learning techniques [12]. The drawback of these approaches, e.g. the work described in [6], however, was their rather strong focus on structured knowledge or data bases, from which they induced their rules. 
\fs24 \uc0\u8232 
\fs29\fsmilli14667 In contrast, in the Web environment that we encounter when building Web ontologies, the struc- tured knowledge or data base is rather the exception than the norm. Hence, intelligent means for an ontology engineer takes on a different meaning than the \'97 very seminal \'97 integration architectures for more conventional knowledge acquisition [1]. 
\fs24 \uc0\u8232 
\fs29\fsmilli14667 Our notion of 
\i Ontology Learning 
\i0 aims at the integration of a multitude of disciplines in order to facilitate the construction of ontologies, in particular machine learning. Because the fully auto- matic acquisition of knowledge by machines remains in the distant future, we consider the process of ontology learning as semi-automatic with human intervention, adopting the paradigm of 
\i balanced cooperative modeling 
\i0 [5] for the construction of ontologies for the Semantic Web. This objective in mind, we have built an architecture that combines knowledge acquisition with machine learning, feeding on the resources that we nowadays find on the syntactic Web, 
\i viz. 
\i0 free text, semi-structured text, schema definitions (DTDs), etc. Thereby, modules in our framework serve different steps in the engineering cycle, which here consists of the following five steps (cf. Figure 1): 
\fs24 \uc0\u8232 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 2 
\fs24 \

\fs29\fsmilli14667 First, existing ontologies are 
\b imported 
\b0 and 
\b reused 
\b0 by merging existing structures or defining mapping rules between existing structures and the ontology to be established. For instance, [9] de- scribe how ontological structures contained in Cyc are used in order to facilitate the construction of a domain-specific ontology. Second, in the ontology 
\b extraction 
\b0 phase major parts of the target ontol- ogy are modeled with learning support feeding from web documents. Third, this rough outline of the target ontology needs to be 
\b pruned 
\b0 in order to better adjust the ontology to its prime purpose. Fourth, ontology 
\b refinement 
\b0 profits from the given domain ontology, but completes the ontology at a fine granularity (also in contrast to extraction). Fifth, the prime target application serves as a measure for validating the resulting ontology [11]. Finally, one may revolve again in this cycle, e.g. for including new domains into the constructed ontology or for maintaining and updating its scope. 
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page3image8032.png \width7200 \height5700
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f1\i\b\fs26\fsmilli13333 \cf2 Legacy + Application Data 
\f0\i0\b0\fs24 \

\f1\i\b\fs26\fsmilli13333 Ontology Learning 
\f0\i0\b0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page3image9160.png \width4180 \height4320
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2  {{\NeXTGraphic page3image9920.png \width1656 \height867
}¬} {{\NeXTGraphic page3image10080.png \width808 \height374
}¬} {{\NeXTGraphic page3image10240.png \width1656 \height867
}¬}\
\pard\pardeftab720\sl360\sa240\partightenfactor0

\f1\fs32 \cf2 \cb3 Extract 
\f0\fs24 \cb1 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page3image11008.png \width1656 \height1656
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2  {{\NeXTGraphic page3image17144.png \width1656 \height867
}¬}\
\pard\pardeftab720\sl360\sa240\partightenfactor0

\f1\fs32 \cf2 Import / Reuse 
\f0\fs24 \
\pard\pardeftab720\sl200\sa240\partightenfactor0

\f1\i\fs18\fsmilli9333 \cf2 Domain Ontology 
\f0\i0\fs24 \
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f1\i\b\fs26\fsmilli13333 \cf2 Ontology Learning 
\f0\i0\b0\fs24 \
\pard\pardeftab720\sl360\sa240\partightenfactor0

\f1\fs32 \cf2 \cb3 Refine 
\f0\fs24 \cb1 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page3image19440.png \width1656 \height867
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2  {{\NeXTGraphic page3image19600.png \width710 \height532
}¬} {{\NeXTGraphic page3image20024.png \width836 \height720
}¬} {{\NeXTGraphic page3image20448.png \width2447 \height1462
}¬}\
\pard\pardeftab720\sl360\sa240\partightenfactor0

\f1\fs32 \cf2 Apply 
\f0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Figure 1: Ontology Learning process steps 
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page3image21520.png \width505 \height408
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f1\i\b\fs26\fsmilli13333 \cf2 Legacy + Application Data 
\f0\i0\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 3 
\fs24 \
\pard\pardeftab720\sl360\sa240\partightenfactor0

\f1\fs32 \cf2 Prune 
\f0\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\fs37\fsmilli18667 \cf2 ^c 
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page3image23592.png \width1045 \height670
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2  {{\NeXTGraphic page3image21520.png \width505 \height408
}¬} \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 An Architecture for Ontology Learning 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Given the task of constructing and maintaining an ontology for a Semantic Web application, e.g. for an ontology-based knowledge portal that we have been dealing with (cf. [10]), we have produced a wish list of what kind of support we would fancy. 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\b\fs29\fsmilli14667 \cf2 Ontology Engineering Workbench 
\i OntoEdit
\i0 . 
\b0 As core to our approach we have built a graphi- cal user interface to support the ontology engineering process manually performed by the ontology engineer. Here, we offer sophisticated graphical means for manual modeling and refining the final ontology. Different views are offered to the user targeting the epistemological level rather than a par- ticular representation language. However, the ontological structures built there may be exported to standard Semantic Web representation languages, such as OIL and DAML-ONT, as well as our own F-Logic based extensions of RDF(S). In addition, executable representations for constraint check- ing and application debugging can be generated and then accessed via SilRi
\fs21\fsmilli10667 \up10 1
\fs29\fsmilli14667 \up0 , our F-Logic inference engine, that is directly connected with 
\i OntoEdit
\i0 . 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 The sophisticated ontology engineering tools we knew, e.g. the 
\i Prote\uc0\u32 \u769 ge\u32 \u769  
\i0 modeling environment for knowledge-based systems [2], would offer capabilities roughly comparable to 
\i OntoEdit
\i0 . However, given the task of constructing a knowledge portal, we found that there was this large conceptual bridge between the ontology engineering tool and the input (often legacy data), such as Web documents, Web document schemata, databases on the Web, and Web ontologies, which ultimately determined the target ontology. Into this void we have positioned new components of our ontology learning architecture (cf. Figure 2). The new components support the ontology engineer in importing existing ontology primitives, extracting new ones, pruning given ones, or refining with additional ontology primitives. In our case, the ontology primitives comprise: 
\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls2\ilvl0\cf2 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 a set of strings that describe lexical entries for concepts and relations; 
\fs24 \uc0\u8232 \
\ls2\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 asetofconcepts
\fs21\fsmilli10667 \up10 2 
\fs29\fsmilli14667 \up0 \'97
\fs24  
\fs29\fsmilli14667 ; 
\fs24 \uc0\u8232 \
\ls2\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 a taxonomy of concepts with multiple inheritance (heterarchy) ; 
\fs24 \uc0\u8232 \
\ls2\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 a set of non-taxonomic relations \'97 \'97 described by their domain and range restrictions; 
\fs16 \up10 1
\f2\fs24 \up0 http://www.ontoprise.com/ 
\f0 \'97 then 
\f2 download area
\f0 . \uc0\u8232 
\fs16 \up10 2
\fs24 \up0 Concepts in our framework are roughly akin to synsets in WordNet [4]. \uc0\u8232 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page4image18616.png \width822 \height41
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 4 
\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls3\ilvl0\cf2 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 a heterarchy of relations, i.e. a set of taxonomic relations ; 
\fs24 \uc0\u8232 \
\ls3\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 relations and that relate concepts and relations with their lexical entries, respectively; and, 
\fs24 \uc0\u8232 
\fs29\fsmilli14667 finally, 
\fs24 \uc0\u8232 \
\ls3\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 a set of axioms that describe additional constraints on the ontology and allow to make implicit facts explicit [10]. 
\fs24 \uc0\u8232 \
\pard\pardeftab720\sl280\partightenfactor0
\ls4\ilvl0\cf2 {{\NeXTGraphic page5image4000.png \width1680 \height1580
}¬}\ls4\ilvl0\
\pard\pardeftab720\sl200\sa240\partightenfactor0

\f1\fs18\fsmilli9333 \cf2 Web documents 
\f0\fs24 \
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 Legacy databases 
\f0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\ls5\ilvl0\cf2 {{\NeXTGraphic page5image33192.png \width388 \height603
}¬}\ls5\ilvl0 {{\NeXTGraphic page5image33360.png \width388 \height603
}¬} {{\NeXTGraphic page5image33528.png \width386 \height498
}¬} {{\NeXTGraphic page5image33696.png \width1518 \height591
}¬} {{\NeXTGraphic page5image34456.png \width443 \height753
}¬} {{\NeXTGraphic page5image34624.png \width443 \height753
}¬} {{\NeXTGraphic page5image34792.png \width443 \height753
}¬} {{\NeXTGraphic page5image33528.png \width386 \height498
}¬} {{\NeXTGraphic page5image33360.png \width388 \height603
}¬} {{\NeXTGraphic page5image35296.png \width1518 \height512
}¬} {{\NeXTGraphic page5image34456.png \width443 \height753
}¬}\
\pard\pardeftab720\sl160\sa240\partightenfactor0

\fs13\fsmilli6667 \cf2 DTD 
\fs24 \

\fs13\fsmilli6667 DTD 
\fs24 \
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 Import semi- structured schema 
\f0\fs24 \

\f1\fs16 O2 
\f0\fs24 \

\f1\fs16 O1 
\f0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\ls6\ilvl0\cf2 {{\NeXTGraphic page5image38016.png \width4360 \height1480
}¬}\ls6\ilvl0 {{\NeXTGraphic page5image38608.png \width1245 \height603
}¬} {{\NeXTGraphic page5image39032.png \width272 \height583
}¬}\
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 Crawl corpus 
\f0\fs24 \

\f1\fs16 Import schema 
\f0\fs24 \

\f1\fs16 Import existing ontologies 
\f0\fs24 \

\f1\fs16 Ontology WordNet 
\f0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\ls7\ilvl0\cf2 {{\NeXTGraphic page5image41672.png \width256 \height433
}¬}\ls7\ilvl0 {{\NeXTGraphic page5image42096.png \width7080 \height5480
}¬} {{\NeXTGraphic page5image42520.png \width2741 \height907
}¬}\
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f1\fs26\fsmilli13333 \cf2 Management Component 
\f0\fs24 \

\f1\fs26\fsmilli13333 Resource Processing Component 
\f0\fs24 \

\f1\fs26\fsmilli13333 NLP System 
\f0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\ls8\ilvl0\cf2 {{\NeXTGraphic page5image44432.png \width793 \height884
}¬}\ls8\ilvl0 {{\NeXTGraphic page5image44600.png \width4241 \height848
}¬} {{\NeXTGraphic page5image44760.png \width1656 \height848
}¬} {{\NeXTGraphic page5image44920.png \width322 \height113
}¬} {{\NeXTGraphic page5image45512.png \width1360 \height1680
}¬} {{\NeXTGraphic page5image46104.png \width136 \height740
}¬} {{\NeXTGraphic page5image46528.png \width136 \height505
}¬} {{\NeXTGraphic page5image47120.png \width966 \height433
}¬} {{\NeXTGraphic page5image47280.png \width136 \height2296
}¬}\
\pard\pardeftab720\sl240\sa240\partightenfactor0

\f1\fs21\fsmilli10667 \cf2 Ontology Engineer 
\f0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\ls9\ilvl0\cf2 {{\NeXTGraphic page5image48464.png \width185 \height28
}¬}\ls9\ilvl0 {{\NeXTGraphic page5image48624.png \width268 \height806
}¬} {{\NeXTGraphic page5image49048.png \width1360 \height1360
}¬}\
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 ... 
\f0\fs24 \
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 \cb4 Lexicon 
\fs10\fsmilli5333 \dn3 n 
\f0\fs24 \cb1 \up0 \
\pard\pardeftab720\sl280\partightenfactor0
\ls10\ilvl0\cf2 {{\NeXTGraphic page5image55256.png \width710 \height335
}¬}\ls10\ilvl0 {{\NeXTGraphic page5image48464.png \width185 \height28
}¬} {{\NeXTGraphic page5image56168.png \width115 \height307
}¬} {{\NeXTGraphic page5image56760.png \width2782 \height1886
}¬} {{\NeXTGraphic page5image56928.png \width1084 \height591
}¬} {{\NeXTGraphic page5image57520.png \width138 \height611
}¬} {{\NeXTGraphic page5image58112.png \width2110 \height828
}¬} {{\NeXTGraphic page5image58272.png \width927 \height828
}¬}\
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f1\fs26\fsmilli13333 \cf2 Algorithm Library 
\f0\fs24 \
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 Domain Ontology 
\f0\fs24 \
\pard\pardeftab720\sl300\sa240\partightenfactor0

\f1\fs26\fsmilli13333 \cf2 Result Set 
\f0\fs24 \

\f1\fs26\fsmilli13333 OntoEdit 
\f0\fs24 \
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 \cb4 Inference Engine(s) 
\f0\fs24 \cb1 \
\pard\pardeftab720\sl280\partightenfactor0
\ls11\ilvl0\cf2 {{\NeXTGraphic page5image60728.png \width914 \height136
}¬}\ls11\ilvl0\
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Figure 2: Architecture for Learning Ontologies for the Semantic Web 
\fs24 \

\fs29\fsmilli14667 This structure corresponds closely to RDFS, the one exception is the explicit consideration of lexical entries. The separation of concept reference and concept denotation, which may be easily ex- pressed in RDF, allows to provide very domain-specific ontologies without incurring an instantaneous conflict when merging ontologies \'97 a standard request in the Semantic Web. For instance, the lexical entry \'93school\'94 in one ontology may refer to a building in ontology A, but to an organization in ontol- 
\fs24 \

\fs29\fsmilli14667 5 
\fs24 \
\pard\pardeftab720\sl180\sa240\partightenfactor0

\f1\fs16 \cf2 Lexicon 
\fs10\fsmilli5333 \dn3 1 
\f0\fs24 \up0 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 ogy B, or to both in ontology C. Also in ontology A the concept refered to in English by \'93school\'94 and \'93school building\'94 may be referred to in German by \'93Schule\'94 and \'93Schulgeba\uc0\u32 \u776 ude\'94. 
\fs24 \

\fs29\fsmilli14667 Ontology learning relies on ontology structures given along these lines and on input data as de- scribed above in order to propose new knowledge about reasonably interesting concepts, relations, lexical entries, or about links between these entities \'97 proposing the addition, the deletion, or the merging of some of them. The results of the ontology learning process are presented to the ontology engineer by the graphical result set representation (cf. Figure 4 for an example of how extracted prop- erties may be presented). The ontology engineer may then browse the results and decide to follow, delete, or modify the proposals in accordance to the purpose of her task. 
\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 Components for Learning Ontologies 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Integrating the considerations from above into a coherent generic architecture for extracting and main- taining ontologies from data on the Web we have identified several core components. There are, 
\i (i)
\i0 , a generic management component dealing with delegation of tasks and constituting the infrastructure backbone, 
\i (ii)
\i0 , a resource processing component working on input data from the Web including, in particular, a natural language processing system, 
\i (iii)
\i0 , an algorithm library working on the output of the resource processing component as well as the ontology structures sketched above and return- ing result sets also mentioned above and, 
\i (iv)
\i0 , the graphical user interface for ontology engineering, 
\i OntoEdit
\i0 . 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\b\fs29\fsmilli14667 \cf2 Management component. 
\b0 The ontology engineer uses the management component to select input data, i.e. relevant resources such as HTML & XML documents, document type definitions, databases, or existing ontologies that are exploited in the further discovery process. Secondly, using the man- agement component, the ontology engineer also chooses among a set of resource processing methods available at the resource processing component and among a set of algorithms available in the algo- rithm library. 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Furthermore, the management component even supports the ontology engineer in discovering task-relevant legacy data, e.g. an ontology-based crawler gathers HTML documents that are relevant to a given core ontology and an RDF crawler follows URIs (i.e., unique identifiers in XML/RDF) that are also URLs in order to cover parts of the so far tiny, but growing Semantic Web. 
\fs24 \

\fs29\fsmilli14667 6 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\b\fs29\fsmilli14667 \cf2 Resource processing component. 
\b0 Resource processing strategies differ depending on the type of input data made available: 
\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sa240\partightenfactor0
\ls12\ilvl0\cf2 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 HTML documents may be indexed and reduced to free text. 
\fs24 \uc0\u8232 \
\ls12\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 Semi-structured documents, like dictionaries, may be transformed into a predefined relational 
\fs24 \uc0\u8232 
\fs29\fsmilli14667 structure. 
\fs24 \uc0\u8232 \
\ls12\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 Semi-structured and structured schema data (like DTD\'92s, structured database schemata, and existing ontologies) are handeled following different strategies for import as described later in this paper. 
\fs24 \uc0\u8232 \
\ls12\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\'a0
\fs29\fsmilli14667 For processing free natural text our system accesses the natural language processing system SMES (Saarbru\uc0\u32 \u776 cken Message Extraction System), a shallow text processor for German (cf. [7]). SMES comprises a 
\i tokenizer 
\i0 based on regular expressions, a 
\i lexical analysis 
\i0 component including various word 
\i lexicons
\i0 , a 
\i morphological analysis 
\i0 module, a 
\i named entity recognizer
\i0 , a 
\i part-of-speech tagger 
\i0 and a 
\i chunk parser
\i0 . 
\fs24 \uc0\u8232 
\fs29\fsmilli14667 After first preprocessing according to one of these or similar strategies, the resource processing module transforms the data into an algorithm-specific relational representation. 
\fs24 \uc0\u8232 
\b\fs29\fsmilli14667 Algorithm Library. 
\b0 As described above an ontology may be described by a number of sets of concepts, relations, lexical entries, and links between these entities. An existing ontology definition (including ) may be acquired using various algorithms working on this def- inition and the preprocessed input data. While specific algorithms may greatly vary from one type of input to the next, there is also considerable overlap concerning underlying learning approaches like association rules, formal concept analysis, or clustering. Hence, we may reuse algorithms from the library for acquiring different parts of the ontology definition. 
\fs24 \uc0\u8232 
\fs29\fsmilli14667 Subsequently, we introduce some of these algorithms available in our implementation. In general, we use a multi-strategy learning and result combination approach, i.e. each algorithm that is plugged into the library generates normalized results that adhere to the ontology structures sketched above and that may be combined into a coherent ontology definition. 
\fs24 \uc0\u8232 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 7 
\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 Import & Reuse 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Given our experiences in medicine, telecommunication, and insurance, we expect that for almost any commercially significant domain there are some kind of domain conceptualizations available. Thus, we need mechanisms and strategies to 
\i import & reuse 
\i0 domain conceptualizations from existing (schema) structures. Thereby, the conceptualizations may be recovered, e.g., from legacy database schemata, document-type definitions (DTDs), or from existing ontologies that conceptualize some relevant part of the target ontology. 
\fs24 \

\fs29\fsmilli14667 In the first part of the 
\i import & reuse 
\i0 step, the schema structures are identified and their general content need to be discussed with domain experts. Each of these knowledge sources must be im- ported separately. Import may be performed manually \'97 which may include the manual definition of transformation rules. Alternatively, reverse engineering tools, such as exist for recovering extended entity-relationship diagrams from the SQL description of a given database (cf. reference [19, 11] in survey, Table 1), may facilitate the recovery of conceptual structures. 
\fs24 \

\fs29\fsmilli14667 In the second part of the 
\i import & reuse 
\i0 step, imported conceptual structures need to be merged or aligned in order to constitute a single common ground from which to take-off into the subsequent ontology learning phases of 
\i extracting
\i0 , 
\i pruning 
\i0 and 
\i refining
\i0 . While the general research issue con- cerning merging and aligning is still an open problem, recent proposals (e.g., [8]) have shown how to improve the manual process of merging/aligning. Existing methods for merging/aligning mostly rely on matching heuristics for proposing the merge of concepts and similar knowledge-base operations. Our current research also integrates mechanisms that use a application data oriented, bottom-up ap- proach. For instance, formal concept analysis allows to discover patterns between application data on the one hand and the usage of concepts and relations and the semantics given by their heterarchies on the other hand in a formally concise way (cf. reference [7] in survey, Table 1, on formal concept analysis). 
\fs24 \

\fs29\fsmilli14667 Overall, the import and reuse step in ontology learning seems to be the one that is the hardest to generalize. The task may remind vaguely of the general problems with data warehousing adding, however, challenging problems of its own. 
\fs24 \

\fs29\fsmilli14667 8 
\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 Extracting Ontologies 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 In the ontology extraction phase of the ontology learning process, major parts, i.e. the complete on- tology or large chunks reflecting a new subdomain of the ontology, are modeled with learning support exploiting various types of (Web) sources. Thereby, ontology learning techniques partially rely on given ontology parts. Thus, we here encounter an iterative model where previous revisions through the ontology learning cycle may propel subsequent ones and more sophisticated algorithms may work on structures proposed by more straightforward ones before. 
\fs24 \

\fs29\fsmilli14667 Describing this phase, we sketch some of the techniques and algorithms that have been embedded in our framework and implemented in our ontology learning environment 
\i Text-To-Onto 
\i0 (cf. Figure 3). Doing so, we cover a very substantial part of the overall ontology learning task in the extraction phase. 
\i Text-To-Onto 
\i0 proposes many different ontology components, which we have described above (i.e. ), to the ontology engineer feeding on several types of input. 
\fs24 \

\fs29\fsmilli14667 Figure 3: Screenshot of our Ontology Learning Workbench 
\i Text-To-Onto 
\i0\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page9image9336.png \width8573 \height6228
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 9 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\b\fs29\fsmilli14667 \cf2 Lexical Entry & Concept Extraction. 
\b0 This technique is one of the baseline methods applied in our framework for acquiring lexical entries with corresponding concepts. In 
\i Text-To-Onto
\i0 , web documents are morphologically processed, including the treatment of multi-word terms such as \'93database reverse engineering\'94 by N-grams, a simple statistics means. Based on this text preprocessing, term extraction techniques, which are based on (weighted) statistical frequencies, are applied in order to propose new lexical entries for . 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Often, the ontology engineer follows the proposal by the lexical entry & concept extraction mech- anism and includes a new lexical entry in the ontology. Because the new lexical entry comes without an associated concept, the ontology engineer must then decide (possibly with help from further pro- cessing) whether to introduce a new concept or link the new lexical entry to an existing concept. 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\b\fs29\fsmilli14667 \cf2 Hierarchical Concept Clustering. 
\b0 Given a lexicon and a set of concepts, one major next step is the taxonomic classification of concepts. One generally applicable method with to this regard is hierarchical clustering. Hierarchical clustering exploits the similarity of items in order to propose a hierarchy of item categories. The similarity measure is defined on the properties of items. 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Given the task of extracting a hierarchy from natural language text, adjacency of terms or syntacti- cal relationships between terms are two properties that yield considerable descriptive power to induce the semantic hierarchy of concepts related to these terms. 
\fs24 \

\fs29\fsmilli14667 A sophisticated example for hierarchical clustering is given by Faure & Nedellec (cf. reference [6] in survey, Table 1): They present a cooperative machine learning system, ASIUM, which acquires taxonomic relations and subcategorization frames of verbs based on syntactic input. The ASIUM system hierarchically clusters nouns based on the verbs that they are syntactically related with and 
\i vice versa
\i0 . Thus, they cooperatively extend the lexicon, the set of concepts, and the concept heterarchy (
\fs24  
\fs29\fsmilli14667 ). 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\b\fs29\fsmilli14667 \cf2 Dictionary Parsing. 
\b0 Machine-readable dictionaries (MRD) are frequently available for many do- mains. Though their internal structure is free text to a large extent, there are comparatively few patterns that are used to give text definitions. Hence, MRDs exhibit a large degree of regularity that may be exploited for extracting a domain conceptualization and proposing it to the ontology engineer. 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\i\fs29\fsmilli14667 \cf2 Text-To-Onto 
\i0 has been used to generate a taxonomy of concepts from a machine-readable dictio- nary of an insurance company (cf. reference [13] in survey, Table 1). Likewise to term extraction from free text morphological processing is applied, this time however complementing several pattern- 
\fs24 \

\fs29\fsmilli14667 10 
\fs24 \

\fs29\fsmilli14667 matching heuristics. For example the dictionary contained the following entry: 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\i\b\fs29\fsmilli14667 \cf2 Automatic Debit Transfer: 
\b0 Electronic service arising from a debit authorization of the Yellow Account holder for a recipient to debit bills that fall due direct from the account.
\i0 . 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Several heuristics were applied to the morphologically analyzed definitions. For instance, one simple heuristic relates the definition term, here \'93automatic debit transfer\'94, with the first noun phrase occurring in the definition, here \'93electronic service\'94. Their corresponding concepts are linked in the heterarchy : (
\fs24 AUTOMATIC DEBIT TRANSFER
\fs29\fsmilli14667 , 
\fs24 ELECTRONIC SERVICE
\fs29\fsmilli14667 ). Applying this heuristic iteratively, one may propose large parts of the target ontology, more precisely and to the ontology engineer. In fact, because verbs tend to be modeled as relations, (and the linkage between and ) may be extended by this way, too. 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\b\fs29\fsmilli14667 \cf2 Association Rules. 
\b0 Association rule learning algorithms are typically used for prototypical applica- tions of data mining, like finding associations that occur between items, e.g. supermarket products, in a set of transactions, e.g. customers\'92 purchases. The generalized association rule learning algorithm extends its baseline by aiming at descriptions at the appropriate level of the taxonomy, e.g. \'93snacks are purchased together with drinks\'94 rather than \'93chips are purchased with beer\'94 and \'93peanuts are purchased with soda\'94. 
\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 In 
\i Text-To-Onto 
\i0 (cf. reference [14] in survey, Table 1) we use a modification of the generalized association rule learning algorithm for discovering properties between classes. A given class hierarchy serves as background knowledge. Pairs of syntactically related classes (e.g. pair(
\fs24 FESTIVAL
\fs29\fsmilli14667 ,
\fs24 ISLAND
\fs29\fsmilli14667 ) describing the head-modifier relationship contained in the sentence \'93The festival on Usedom
\fs21\fsmilli10667 \up10 3 
\fs29\fsmilli14667 \up0 attracts tourists from all over the world.\'94) are given as input to the algorithm. The algorithm generates asso- ciation rules comparing the relevance of different rules while climbing up and/or down the taxonomy. The appearingly most relevant binary rules are proposed to the ontology engineer for modeling rela- tions into the ontology, thus extending . 
\fs24 \

\fs29\fsmilli14667 As the number of generated rules is typically high, we offer various modes of interaction. For example, it is possible to restrict the number of suggested relations by defining so-called restriction classes that have to participate in the relations that are extracted. Another way of focusing is the flexible enabling / disabling of the use of taxonomic knowledge for extracting relations. 
\fs24 \
\pard\pardeftab720\sl180\sa240\partightenfactor0

\fs16 \cf2 \up10 3
\fs24 \up0 Usedom is an island located in north-east of Germany in the Baltic Sea. \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page4image18616.png \width822 \height41
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 11 
\fs24 \

\fs29\fsmilli14667 Results are presented offering various views onto the results as depicted in Figure 4. A generalized relation that may be induced by the partially given example data above may be the 
\fs21\fsmilli10667 PROPERTY
\fs29\fsmilli14667 (
\fs24 EVENT
\fs29\fsmilli14667 ,
\fs24 AREA
\fs29\fsmilli14667 ), which may be named by the ontology engineer as 
\fs21\fsmilli10667 LOCATED
\fs26\fsmilli13333 I
\fs21\fsmilli10667 N
\fs29\fsmilli14667 , 
\i viz. 
\i0\fs24 EVENTS 
\fs29\fsmilli14667 are located in an 
\fs24 AREA\uc0\u8232 
\fs29\fsmilli14667 (thus extending and ). The user may add the extracted relations to the ontology by drag-and-drop.\uc0\u8232 To explore and determine the right aggregation level of adding a relation to the ontology, the user\u8232 may browse the hierarchy view on extracted properties as given in the left part of Figure 4. This view\u8232 may also support the ontology engineer in defining appropriate 
\fs21\fsmilli10667 SUB
\fs26\fsmilli13333 P
\fs21\fsmilli10667 ROPERTY
\fs26\fsmilli13333 O
\fs21\fsmilli10667 F 
\fs29\fsmilli14667 relations between properties, such as 
\fs21\fsmilli10667 SUB
\fs26\fsmilli13333 P
\fs21\fsmilli10667 ROPERTY
\fs26\fsmilli13333 O
\fs21\fsmilli10667 F
\fs29\fsmilli14667 (
\fs21\fsmilli10667 HAS
\fs26\fsmilli13333 D
\fs21\fsmilli10667 OUBLE
\fs26\fsmilli13333 R
\fs21\fsmilli10667 OOM
\fs29\fsmilli14667 ,
\fs21\fsmilli10667 HAS
\fs26\fsmilli13333 R
\fs21\fsmilli10667 OOM
\fs29\fsmilli14667 ) (thereby extending ). 
\fs24 \

\fs29\fsmilli14667 Figure 4: Result Presentation in 
\i Text-To-Onto 
\i0\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 Pruning the Ontology 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 A common theme of modeling in various disciplines is the balance between completeness and scarcity of the domain model. It is a widely held belief that targeting completeness for the domain model on the one hand appears to be practically inmanagable and computationally intractable, and targeting the scarcest model on the other hand is overly limiting with regard to expressiveness. Hence, what we strive for is the balance between these two, which is really working. We aim at a model that captures a rich conceptualization of the target domain, but that excludes parts that are out of its focus. The 
\i import & reuse 
\i0 of ontologies as well as the 
\i extraction 
\i0 of ontologies considerably pull the lever of 
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 {{\NeXTGraphic page12image12760.png \width5305 \height3820
}¬}\pard\pardeftab720\sl280\partightenfactor0
\cf2  {{\NeXTGraphic page12image12928.png \width4005 \height2523
}¬}\
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 12 
\fs24 \

\fs29\fsmilli14667 the scale into the imbalance where out-of-focus concepts reign. Therefore, we pursue the appropriate diminishing of the ontology in the 
\i pruning 
\i0 phase. 
\fs24 \

\fs29\fsmilli14667 There are at least two dimensions to look at the problem of pruning. First, one needs to clarify how the pruning of particular parts of the ontology (e.g., the removal of a concept or a relation) affects the rest. For instance, Peterson 
\i et. al. 
\i0 [9] have described strategies that leave the user with a coher- ent ontology (i.e. no dangling or broken links). Second, one may consider strategies for proposing ontology items that should be either kept or pruned. We have investigated several mechanisms for generating proposals from application data Given a set of application-specific documents there are several strategies for pruning the ontology. They are based on absolute or relative counts of frequency of terms (cf. reference [13] in survey, Table 1). 
\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 Refining the Ontology 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\i\fs29\fsmilli14667 \cf2 Refining 
\i0 plays a similar role as 
\i extracting
\i0 . Their difference exists rather on a sliding scale than by a clear-cut distinction. While extracting serves mostly for cooperative modeling of the overall ontology (or at least of very significant chunks of it), the refinement phase is about fine tuning the target ontol- ogy and the support of its evolving nature. The refinement phase may use data that comes from the concrete Semantic Web application, e.g. log files of user queries or generic user data. Adapting and refining the ontology with respect to user requirements plays a major role for the acceptance of the application and its further development. 
\fs24 \

\fs29\fsmilli14667 In principle, the same algorithms may be used for extraction as for refinement. However, during refinement one must consider in detail the existing ontology and the existing connections into the ontology, while extraction works more often than not practically from scratch. 
\fs24 \

\fs29\fsmilli14667 A prototypical approach for refinement (though not for extraction!) has been presented by Hahn & Schnattinger (cf. reference [8] in survey, Table 1). They have introduced a methodology for au- tomating the maintenance of domain-specific taxonomies. An ontology is 
\i incrementally 
\i0 updated as new concepts are acquired from text. The acquisition process is centered around the linguistic and conceptual \'93quality\'94 of various forms of evidence underlying the generation and refinement of con- cept hypothesis. In particular they consider semantic conflicts and analogous semantic structures from the knowledge base into the ontology in order to determine the quality of a particular proposal. Thus, they extend an existing ontology with new lexical entries for , new concepts for and new relations 
\fs24 \

\fs29\fsmilli14667 13 
\fs24 \

\fs29\fsmilli14667 for . 
\fs24 \
\pard\pardeftab720\sl440\sa240\partightenfactor0

\b\fs37\fsmilli18667 \cf2 Challenges 
\b0\fs24 \
\pard\pardeftab720\sl340\sa240\partightenfactor0

\fs29\fsmilli14667 \cf2 Ontology Learning may add significant leverage to the Semantic Web, because it propels the construc- tion of domain ontologies, which are needed fastly and cheaply for the Semantic Web to succeed. We have presented a comprehensive framework for Ontology Learning that crosses the boundaries of single disciplines, touching on a number of challenges. Table 1 gives a survey of what types of tech- niques should be included in a full-fledged ontology learning and engineering environment. The good news however is that one does not need perfect or optimal support for cooperative modeling of ontolo- gies. At least according to our experience \'93cheap\'94 methods in an integrated environment may yield tremendous help for the ontology engineer. 
\fs24 \

\fs29\fsmilli14667 While a number of problems remain with the single disciplines, some more challenges come up regarding the particular problem of Ontology Learning for the Semantic Web. First, with the XML-based namespace mechanisms the notion of an ontology with well-defined boundaries, e.g. only definitions that are in one file, will disappear. Rather, the Semantic Web may yield an \'93amoeba- like\'94 structure regarding ontology boundaries, because ontologies refer to each other and import each other (cf. e.g. the DAML-ONT primitive 
\f2 import
\f0 ). However, it is not yet clear how the semantics of these structures will look like. In light of these facts the importance of methods like ontology pruning and crawling of ontologies will drastically increase still. Second, we have so far restricted our attention in ontology learning to the conceptual structures that are (almost) contained in RDF(S) proper. Additional semantic layers on top of RDF (e.g. future OIL or DAML-ONT with axioms, ) will require new means for improved ontology engineering with axioms, too! 
\fs24 \
}